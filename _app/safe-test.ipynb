{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9331e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safetensor Header:\n",
      "{\n",
      "  \"__metadata__\": {\n",
      "    \"format\": \"pt\"\n",
      "  },\n",
      "  \"model.embed_tokens.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      102400,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      0,\n",
      "      419430400\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      419430400,\n",
      "      436207616\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      436207616,\n",
      "      452984832\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      452984832,\n",
      "      469762048\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      469762048,\n",
      "      469766144\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      469766144,\n",
      "      469770240\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      469770240,\n",
      "      469770368\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      469770368,\n",
      "      471867520\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      471867520,\n",
      "      480256128\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      480256128,\n",
      "      480256256\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      480256256,\n",
      "      488644864\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.0.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      488644864,\n",
      "      490742016\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      490742016,\n",
      "      507519232\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      507519232,\n",
      "      524296448\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      524296448,\n",
      "      541073664\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      541073664,\n",
      "      541077760\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      541077760,\n",
      "      541081856\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      541081856,\n",
      "      541081984\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      541081984,\n",
      "      543179136\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      543179136,\n",
      "      551567744\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      551567744,\n",
      "      551567872\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      551567872,\n",
      "      559956480\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.1.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      559956480,\n",
      "      562053632\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      562053632,\n",
      "      578830848\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      578830848,\n",
      "      595608064\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      595608064,\n",
      "      612385280\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      612385280,\n",
      "      612389376\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      612389376,\n",
      "      612393472\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      612393472,\n",
      "      612393600\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      612393600,\n",
      "      614490752\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      614490752,\n",
      "      622879360\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      622879360,\n",
      "      622879488\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      622879488,\n",
      "      631268096\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.10.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      631268096,\n",
      "      633365248\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      633365248,\n",
      "      650142464\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      650142464,\n",
      "      666919680\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      666919680,\n",
      "      683696896\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      683696896,\n",
      "      683700992\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      683700992,\n",
      "      683705088\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      683705088,\n",
      "      683705216\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      683705216,\n",
      "      685802368\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      685802368,\n",
      "      694190976\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      694190976,\n",
      "      694191104\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      694191104,\n",
      "      702579712\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.11.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      702579712,\n",
      "      704676864\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      704676864,\n",
      "      721454080\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      721454080,\n",
      "      738231296\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      738231296,\n",
      "      755008512\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      755008512,\n",
      "      755012608\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      755012608,\n",
      "      755016704\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      755016704,\n",
      "      755016832\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      755016832,\n",
      "      757113984\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      757113984,\n",
      "      765502592\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      765502592,\n",
      "      765502720\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      765502720,\n",
      "      773891328\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.12.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      773891328,\n",
      "      775988480\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      775988480,\n",
      "      792765696\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      792765696,\n",
      "      809542912\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      809542912,\n",
      "      826320128\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      826320128,\n",
      "      826324224\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      826324224,\n",
      "      826328320\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      826328320,\n",
      "      826328448\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      826328448,\n",
      "      828425600\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      828425600,\n",
      "      836814208\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      836814208,\n",
      "      836814336\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      836814336,\n",
      "      845202944\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.13.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      845202944,\n",
      "      847300096\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      847300096,\n",
      "      864077312\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      864077312,\n",
      "      880854528\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      880854528,\n",
      "      897631744\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      897631744,\n",
      "      897635840\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      897635840,\n",
      "      897639936\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      897639936,\n",
      "      897640064\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      897640064,\n",
      "      899737216\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      899737216,\n",
      "      908125824\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      908125824,\n",
      "      908125952\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      908125952,\n",
      "      916514560\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.14.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      916514560,\n",
      "      918611712\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      918611712,\n",
      "      935388928\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      935388928,\n",
      "      952166144\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      952166144,\n",
      "      968943360\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      968943360,\n",
      "      968947456\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      968947456,\n",
      "      968951552\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      968951552,\n",
      "      968951680\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      968951680,\n",
      "      971048832\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      971048832,\n",
      "      979437440\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      979437440,\n",
      "      979437568\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      979437568,\n",
      "      987826176\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.15.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      987826176,\n",
      "      989923328\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      989923328,\n",
      "      1006700544\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1006700544,\n",
      "      1023477760\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1023477760,\n",
      "      1040254976\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1040254976,\n",
      "      1040259072\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1040259072,\n",
      "      1040263168\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1040263168,\n",
      "      1040263296\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1040263296,\n",
      "      1042360448\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1042360448,\n",
      "      1050749056\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1050749056,\n",
      "      1050749184\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1050749184,\n",
      "      1059137792\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.16.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1059137792,\n",
      "      1061234944\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1061234944,\n",
      "      1078012160\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1078012160,\n",
      "      1094789376\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1094789376,\n",
      "      1111566592\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1111566592,\n",
      "      1111570688\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1111570688,\n",
      "      1111574784\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1111574784,\n",
      "      1111574912\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1111574912,\n",
      "      1113672064\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1113672064,\n",
      "      1122060672\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1122060672,\n",
      "      1122060800\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1122060800,\n",
      "      1130449408\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.17.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1130449408,\n",
      "      1132546560\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1132546560,\n",
      "      1149323776\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1149323776,\n",
      "      1166100992\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1166100992,\n",
      "      1182878208\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1182878208,\n",
      "      1182882304\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1182882304,\n",
      "      1182886400\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1182886400,\n",
      "      1182886528\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1182886528,\n",
      "      1184983680\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1184983680,\n",
      "      1193372288\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1193372288,\n",
      "      1193372416\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1193372416,\n",
      "      1201761024\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.18.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1201761024,\n",
      "      1203858176\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1203858176,\n",
      "      1220635392\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1220635392,\n",
      "      1237412608\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1237412608,\n",
      "      1254189824\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1254189824,\n",
      "      1254193920\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1254193920,\n",
      "      1254198016\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1254198016,\n",
      "      1254198144\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1254198144,\n",
      "      1256295296\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1256295296,\n",
      "      1264683904\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1264683904,\n",
      "      1264684032\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1264684032,\n",
      "      1273072640\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.19.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1273072640,\n",
      "      1275169792\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1275169792,\n",
      "      1291947008\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1291947008,\n",
      "      1308724224\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1308724224,\n",
      "      1325501440\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1325501440,\n",
      "      1325505536\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1325505536,\n",
      "      1325509632\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1325509632,\n",
      "      1325509760\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1325509760,\n",
      "      1327606912\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1327606912,\n",
      "      1335995520\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1335995520,\n",
      "      1335995648\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1335995648,\n",
      "      1344384256\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.2.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1344384256,\n",
      "      1346481408\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1346481408,\n",
      "      1363258624\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1363258624,\n",
      "      1380035840\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1380035840,\n",
      "      1396813056\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1396813056,\n",
      "      1396817152\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1396817152,\n",
      "      1396821248\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1396821248,\n",
      "      1396821376\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1396821376,\n",
      "      1398918528\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1398918528,\n",
      "      1407307136\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1407307136,\n",
      "      1407307264\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1407307264,\n",
      "      1415695872\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.20.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1415695872,\n",
      "      1417793024\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1417793024,\n",
      "      1434570240\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1434570240,\n",
      "      1451347456\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1451347456,\n",
      "      1468124672\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1468124672,\n",
      "      1468128768\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1468128768,\n",
      "      1468132864\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1468132864,\n",
      "      1468132992\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1468132992,\n",
      "      1470230144\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1470230144,\n",
      "      1478618752\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1478618752,\n",
      "      1478618880\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1478618880,\n",
      "      1487007488\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.21.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1487007488,\n",
      "      1489104640\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1489104640,\n",
      "      1505881856\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1505881856,\n",
      "      1522659072\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1522659072,\n",
      "      1539436288\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1539436288,\n",
      "      1539440384\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1539440384,\n",
      "      1539444480\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1539444480,\n",
      "      1539444608\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1539444608,\n",
      "      1541541760\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1541541760,\n",
      "      1549930368\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1549930368,\n",
      "      1549930496\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1549930496,\n",
      "      1558319104\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.22.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1558319104,\n",
      "      1560416256\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1560416256,\n",
      "      1577193472\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1577193472,\n",
      "      1593970688\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1593970688,\n",
      "      1610747904\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1610747904,\n",
      "      1610752000\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1610752000,\n",
      "      1610756096\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1610756096,\n",
      "      1610756224\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1610756224,\n",
      "      1612853376\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1612853376,\n",
      "      1621241984\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1621241984,\n",
      "      1621242112\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1621242112,\n",
      "      1629630720\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.23.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1629630720,\n",
      "      1631727872\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1631727872,\n",
      "      1648505088\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1648505088,\n",
      "      1665282304\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1665282304,\n",
      "      1682059520\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1682059520,\n",
      "      1682063616\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1682063616,\n",
      "      1682067712\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1682067712,\n",
      "      1682067840\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1682067840,\n",
      "      1684164992\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1684164992,\n",
      "      1692553600\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1692553600,\n",
      "      1692553728\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1692553728,\n",
      "      1700942336\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.24.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1700942336,\n",
      "      1703039488\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1703039488,\n",
      "      1719816704\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1719816704,\n",
      "      1736593920\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1736593920,\n",
      "      1753371136\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1753371136,\n",
      "      1753375232\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1753375232,\n",
      "      1753379328\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1753379328,\n",
      "      1753379456\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1753379456,\n",
      "      1755476608\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1755476608,\n",
      "      1763865216\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1763865216,\n",
      "      1763865344\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1763865344,\n",
      "      1772253952\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.25.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1772253952,\n",
      "      1774351104\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1774351104,\n",
      "      1791128320\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1791128320,\n",
      "      1807905536\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1807905536,\n",
      "      1824682752\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1824682752,\n",
      "      1824686848\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1824686848,\n",
      "      1824690944\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1824690944,\n",
      "      1824691072\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1824691072,\n",
      "      1826788224\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1826788224,\n",
      "      1835176832\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1835176832,\n",
      "      1835176960\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1835176960,\n",
      "      1843565568\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.26.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1843565568,\n",
      "      1845662720\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1845662720,\n",
      "      1862439936\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1862439936,\n",
      "      1879217152\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1879217152,\n",
      "      1895994368\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1895994368,\n",
      "      1895998464\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1895998464,\n",
      "      1896002560\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1896002560,\n",
      "      1896002688\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1896002688,\n",
      "      1898099840\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1898099840,\n",
      "      1906488448\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1906488448,\n",
      "      1906488576\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1906488576,\n",
      "      1914877184\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.27.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1914877184,\n",
      "      1916974336\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1916974336,\n",
      "      1933751552\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1933751552,\n",
      "      1950528768\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1950528768,\n",
      "      1967305984\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1967305984,\n",
      "      1967310080\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1967310080,\n",
      "      1967314176\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1967314176,\n",
      "      1967314304\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1967314304,\n",
      "      1969411456\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1969411456,\n",
      "      1977800064\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1977800064,\n",
      "      1977800192\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1977800192,\n",
      "      1986188800\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.28.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1986188800,\n",
      "      1988285952\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      1988285952,\n",
      "      2005063168\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2005063168,\n",
      "      2021840384\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2021840384,\n",
      "      2038617600\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2038617600,\n",
      "      2038621696\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2038621696,\n",
      "      2038625792\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2038625792,\n",
      "      2038625920\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2038625920,\n",
      "      2040723072\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2040723072,\n",
      "      2049111680\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2049111680,\n",
      "      2049111808\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2049111808,\n",
      "      2057500416\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.29.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2057500416,\n",
      "      2059597568\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2059597568,\n",
      "      2076374784\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2076374784,\n",
      "      2093152000\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2093152000,\n",
      "      2109929216\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2109929216,\n",
      "      2109933312\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2109933312,\n",
      "      2109937408\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2109937408,\n",
      "      2109937536\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2109937536,\n",
      "      2112034688\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2112034688,\n",
      "      2120423296\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2120423296,\n",
      "      2120423424\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2120423424,\n",
      "      2128812032\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.3.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2128812032,\n",
      "      2130909184\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2130909184,\n",
      "      2147686400\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2147686400,\n",
      "      2164463616\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2164463616,\n",
      "      2181240832\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2181240832,\n",
      "      2181244928\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2181244928,\n",
      "      2181249024\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2181249024,\n",
      "      2181249152\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2181249152,\n",
      "      2183346304\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2183346304,\n",
      "      2191734912\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2191734912,\n",
      "      2191735040\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2191735040,\n",
      "      2200123648\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.4.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2200123648,\n",
      "      2202220800\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2202220800,\n",
      "      2218998016\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2218998016,\n",
      "      2235775232\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2235775232,\n",
      "      2252552448\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2252552448,\n",
      "      2252556544\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2252556544,\n",
      "      2252560640\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2252560640,\n",
      "      2252560768\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2252560768,\n",
      "      2254657920\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2254657920,\n",
      "      2263046528\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2263046528,\n",
      "      2263046656\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2263046656,\n",
      "      2271435264\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.5.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2271435264,\n",
      "      2273532416\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2273532416,\n",
      "      2290309632\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2290309632,\n",
      "      2307086848\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2307086848,\n",
      "      2323864064\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2323864064,\n",
      "      2323868160\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2323868160,\n",
      "      2323872256\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2323872256,\n",
      "      2323872384\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2323872384,\n",
      "      2325969536\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2325969536,\n",
      "      2334358144\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2334358144,\n",
      "      2334358272\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2334358272,\n",
      "      2342746880\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.6.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2342746880,\n",
      "      2344844032\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2344844032,\n",
      "      2361621248\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2361621248,\n",
      "      2378398464\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2378398464,\n",
      "      2395175680\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2395175680,\n",
      "      2395179776\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2395179776,\n",
      "      2395183872\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2395183872,\n",
      "      2395184000\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2395184000,\n",
      "      2397281152\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2397281152,\n",
      "      2405669760\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2405669760,\n",
      "      2405669888\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2405669888,\n",
      "      2414058496\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.7.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2414058496,\n",
      "      2416155648\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2416155648,\n",
      "      2432932864\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2432932864,\n",
      "      2449710080\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2449710080,\n",
      "      2466487296\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2466487296,\n",
      "      2466491392\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2466491392,\n",
      "      2466495488\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2466495488,\n",
      "      2466495616\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2466495616,\n",
      "      2468592768\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2468592768,\n",
      "      2476981376\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2476981376,\n",
      "      2476981504\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2476981504,\n",
      "      2485370112\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.8.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2485370112,\n",
      "      2487467264\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.mlp.down_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      4096\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2487467264,\n",
      "      2504244480\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.mlp.gate_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2504244480,\n",
      "      2521021696\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.mlp.up_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      4096,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2521021696,\n",
      "      2537798912\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.post_attention_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2537798912,\n",
      "      2537803008\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.post_feedforward_layernorm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2537803008,\n",
      "      2537807104\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.self_attn.k_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2537807104,\n",
      "      2537807232\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.self_attn.k_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2537807232,\n",
      "      2539904384\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.self_attn.o_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2539904384,\n",
      "      2548292992\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.self_attn.q_norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      64\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2548292992,\n",
      "      2548293120\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.self_attn.q_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2548293120,\n",
      "      2556681728\n",
      "    ]\n",
      "  },\n",
      "  \"model.layers.9.self_attn.v_proj.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      512,\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2556681728,\n",
      "      2558778880\n",
      "    ]\n",
      "  },\n",
      "  \"model.norm.weight\": {\n",
      "    \"dtype\": \"BF16\",\n",
      "    \"shape\": [\n",
      "      2048\n",
      "    ],\n",
      "    \"data_offsets\": [\n",
      "      2558778880,\n",
      "      2558782976\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "**************************Metadata:\n",
      "  format: pt\n",
      "\n",
      "**************************Tensors:\n",
      "  model.embed_tokens.weight:\n",
      "    dtype: BF16\n",
      "    shape: [102400, 2048]\n",
      "    data_offsets: [0, 419430400]\n",
      "  model.layers.0.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [419430400, 436207616]\n",
      "  model.layers.0.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [436207616, 452984832]\n",
      "  model.layers.0.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [452984832, 469762048]\n",
      "  model.layers.0.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [469762048, 469766144]\n",
      "  model.layers.0.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [469766144, 469770240]\n",
      "  model.layers.0.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [469770240, 469770368]\n",
      "  model.layers.0.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [469770368, 471867520]\n",
      "  model.layers.0.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [471867520, 480256128]\n",
      "  model.layers.0.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [480256128, 480256256]\n",
      "  model.layers.0.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [480256256, 488644864]\n",
      "  model.layers.0.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [488644864, 490742016]\n",
      "  model.layers.1.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [490742016, 507519232]\n",
      "  model.layers.1.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [507519232, 524296448]\n",
      "  model.layers.1.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [524296448, 541073664]\n",
      "  model.layers.1.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [541073664, 541077760]\n",
      "  model.layers.1.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [541077760, 541081856]\n",
      "  model.layers.1.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [541081856, 541081984]\n",
      "  model.layers.1.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [541081984, 543179136]\n",
      "  model.layers.1.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [543179136, 551567744]\n",
      "  model.layers.1.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [551567744, 551567872]\n",
      "  model.layers.1.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [551567872, 559956480]\n",
      "  model.layers.1.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [559956480, 562053632]\n",
      "  model.layers.10.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [562053632, 578830848]\n",
      "  model.layers.10.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [578830848, 595608064]\n",
      "  model.layers.10.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [595608064, 612385280]\n",
      "  model.layers.10.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [612385280, 612389376]\n",
      "  model.layers.10.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [612389376, 612393472]\n",
      "  model.layers.10.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [612393472, 612393600]\n",
      "  model.layers.10.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [612393600, 614490752]\n",
      "  model.layers.10.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [614490752, 622879360]\n",
      "  model.layers.10.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [622879360, 622879488]\n",
      "  model.layers.10.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [622879488, 631268096]\n",
      "  model.layers.10.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [631268096, 633365248]\n",
      "  model.layers.11.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [633365248, 650142464]\n",
      "  model.layers.11.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [650142464, 666919680]\n",
      "  model.layers.11.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [666919680, 683696896]\n",
      "  model.layers.11.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [683696896, 683700992]\n",
      "  model.layers.11.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [683700992, 683705088]\n",
      "  model.layers.11.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [683705088, 683705216]\n",
      "  model.layers.11.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [683705216, 685802368]\n",
      "  model.layers.11.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [685802368, 694190976]\n",
      "  model.layers.11.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [694190976, 694191104]\n",
      "  model.layers.11.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [694191104, 702579712]\n",
      "  model.layers.11.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [702579712, 704676864]\n",
      "  model.layers.12.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [704676864, 721454080]\n",
      "  model.layers.12.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [721454080, 738231296]\n",
      "  model.layers.12.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [738231296, 755008512]\n",
      "  model.layers.12.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [755008512, 755012608]\n",
      "  model.layers.12.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [755012608, 755016704]\n",
      "  model.layers.12.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [755016704, 755016832]\n",
      "  model.layers.12.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [755016832, 757113984]\n",
      "  model.layers.12.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [757113984, 765502592]\n",
      "  model.layers.12.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [765502592, 765502720]\n",
      "  model.layers.12.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [765502720, 773891328]\n",
      "  model.layers.12.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [773891328, 775988480]\n",
      "  model.layers.13.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [775988480, 792765696]\n",
      "  model.layers.13.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [792765696, 809542912]\n",
      "  model.layers.13.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [809542912, 826320128]\n",
      "  model.layers.13.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [826320128, 826324224]\n",
      "  model.layers.13.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [826324224, 826328320]\n",
      "  model.layers.13.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [826328320, 826328448]\n",
      "  model.layers.13.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [826328448, 828425600]\n",
      "  model.layers.13.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [828425600, 836814208]\n",
      "  model.layers.13.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [836814208, 836814336]\n",
      "  model.layers.13.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [836814336, 845202944]\n",
      "  model.layers.13.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [845202944, 847300096]\n",
      "  model.layers.14.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [847300096, 864077312]\n",
      "  model.layers.14.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [864077312, 880854528]\n",
      "  model.layers.14.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [880854528, 897631744]\n",
      "  model.layers.14.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [897631744, 897635840]\n",
      "  model.layers.14.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [897635840, 897639936]\n",
      "  model.layers.14.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [897639936, 897640064]\n",
      "  model.layers.14.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [897640064, 899737216]\n",
      "  model.layers.14.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [899737216, 908125824]\n",
      "  model.layers.14.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [908125824, 908125952]\n",
      "  model.layers.14.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [908125952, 916514560]\n",
      "  model.layers.14.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [916514560, 918611712]\n",
      "  model.layers.15.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [918611712, 935388928]\n",
      "  model.layers.15.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [935388928, 952166144]\n",
      "  model.layers.15.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [952166144, 968943360]\n",
      "  model.layers.15.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [968943360, 968947456]\n",
      "  model.layers.15.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [968947456, 968951552]\n",
      "  model.layers.15.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [968951552, 968951680]\n",
      "  model.layers.15.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [968951680, 971048832]\n",
      "  model.layers.15.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [971048832, 979437440]\n",
      "  model.layers.15.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [979437440, 979437568]\n",
      "  model.layers.15.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [979437568, 987826176]\n",
      "  model.layers.15.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [987826176, 989923328]\n",
      "  model.layers.16.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [989923328, 1006700544]\n",
      "  model.layers.16.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1006700544, 1023477760]\n",
      "  model.layers.16.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1023477760, 1040254976]\n",
      "  model.layers.16.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1040254976, 1040259072]\n",
      "  model.layers.16.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1040259072, 1040263168]\n",
      "  model.layers.16.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1040263168, 1040263296]\n",
      "  model.layers.16.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1040263296, 1042360448]\n",
      "  model.layers.16.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1042360448, 1050749056]\n",
      "  model.layers.16.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1050749056, 1050749184]\n",
      "  model.layers.16.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1050749184, 1059137792]\n",
      "  model.layers.16.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1059137792, 1061234944]\n",
      "  model.layers.17.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1061234944, 1078012160]\n",
      "  model.layers.17.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1078012160, 1094789376]\n",
      "  model.layers.17.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1094789376, 1111566592]\n",
      "  model.layers.17.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1111566592, 1111570688]\n",
      "  model.layers.17.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1111570688, 1111574784]\n",
      "  model.layers.17.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1111574784, 1111574912]\n",
      "  model.layers.17.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1111574912, 1113672064]\n",
      "  model.layers.17.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1113672064, 1122060672]\n",
      "  model.layers.17.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1122060672, 1122060800]\n",
      "  model.layers.17.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1122060800, 1130449408]\n",
      "  model.layers.17.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1130449408, 1132546560]\n",
      "  model.layers.18.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1132546560, 1149323776]\n",
      "  model.layers.18.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1149323776, 1166100992]\n",
      "  model.layers.18.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1166100992, 1182878208]\n",
      "  model.layers.18.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1182878208, 1182882304]\n",
      "  model.layers.18.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1182882304, 1182886400]\n",
      "  model.layers.18.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1182886400, 1182886528]\n",
      "  model.layers.18.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1182886528, 1184983680]\n",
      "  model.layers.18.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1184983680, 1193372288]\n",
      "  model.layers.18.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1193372288, 1193372416]\n",
      "  model.layers.18.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1193372416, 1201761024]\n",
      "  model.layers.18.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1201761024, 1203858176]\n",
      "  model.layers.19.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1203858176, 1220635392]\n",
      "  model.layers.19.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1220635392, 1237412608]\n",
      "  model.layers.19.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1237412608, 1254189824]\n",
      "  model.layers.19.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1254189824, 1254193920]\n",
      "  model.layers.19.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1254193920, 1254198016]\n",
      "  model.layers.19.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1254198016, 1254198144]\n",
      "  model.layers.19.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1254198144, 1256295296]\n",
      "  model.layers.19.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1256295296, 1264683904]\n",
      "  model.layers.19.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1264683904, 1264684032]\n",
      "  model.layers.19.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1264684032, 1273072640]\n",
      "  model.layers.19.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1273072640, 1275169792]\n",
      "  model.layers.2.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1275169792, 1291947008]\n",
      "  model.layers.2.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1291947008, 1308724224]\n",
      "  model.layers.2.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1308724224, 1325501440]\n",
      "  model.layers.2.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1325501440, 1325505536]\n",
      "  model.layers.2.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1325505536, 1325509632]\n",
      "  model.layers.2.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1325509632, 1325509760]\n",
      "  model.layers.2.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1325509760, 1327606912]\n",
      "  model.layers.2.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1327606912, 1335995520]\n",
      "  model.layers.2.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1335995520, 1335995648]\n",
      "  model.layers.2.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1335995648, 1344384256]\n",
      "  model.layers.2.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1344384256, 1346481408]\n",
      "  model.layers.20.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1346481408, 1363258624]\n",
      "  model.layers.20.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1363258624, 1380035840]\n",
      "  model.layers.20.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1380035840, 1396813056]\n",
      "  model.layers.20.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1396813056, 1396817152]\n",
      "  model.layers.20.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1396817152, 1396821248]\n",
      "  model.layers.20.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1396821248, 1396821376]\n",
      "  model.layers.20.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1396821376, 1398918528]\n",
      "  model.layers.20.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1398918528, 1407307136]\n",
      "  model.layers.20.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1407307136, 1407307264]\n",
      "  model.layers.20.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1407307264, 1415695872]\n",
      "  model.layers.20.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1415695872, 1417793024]\n",
      "  model.layers.21.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1417793024, 1434570240]\n",
      "  model.layers.21.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1434570240, 1451347456]\n",
      "  model.layers.21.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1451347456, 1468124672]\n",
      "  model.layers.21.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1468124672, 1468128768]\n",
      "  model.layers.21.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1468128768, 1468132864]\n",
      "  model.layers.21.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1468132864, 1468132992]\n",
      "  model.layers.21.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1468132992, 1470230144]\n",
      "  model.layers.21.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1470230144, 1478618752]\n",
      "  model.layers.21.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1478618752, 1478618880]\n",
      "  model.layers.21.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1478618880, 1487007488]\n",
      "  model.layers.21.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1487007488, 1489104640]\n",
      "  model.layers.22.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1489104640, 1505881856]\n",
      "  model.layers.22.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1505881856, 1522659072]\n",
      "  model.layers.22.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1522659072, 1539436288]\n",
      "  model.layers.22.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1539436288, 1539440384]\n",
      "  model.layers.22.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1539440384, 1539444480]\n",
      "  model.layers.22.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1539444480, 1539444608]\n",
      "  model.layers.22.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1539444608, 1541541760]\n",
      "  model.layers.22.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1541541760, 1549930368]\n",
      "  model.layers.22.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1549930368, 1549930496]\n",
      "  model.layers.22.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1549930496, 1558319104]\n",
      "  model.layers.22.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1558319104, 1560416256]\n",
      "  model.layers.23.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1560416256, 1577193472]\n",
      "  model.layers.23.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1577193472, 1593970688]\n",
      "  model.layers.23.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1593970688, 1610747904]\n",
      "  model.layers.23.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1610747904, 1610752000]\n",
      "  model.layers.23.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1610752000, 1610756096]\n",
      "  model.layers.23.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1610756096, 1610756224]\n",
      "  model.layers.23.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1610756224, 1612853376]\n",
      "  model.layers.23.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1612853376, 1621241984]\n",
      "  model.layers.23.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1621241984, 1621242112]\n",
      "  model.layers.23.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1621242112, 1629630720]\n",
      "  model.layers.23.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1629630720, 1631727872]\n",
      "  model.layers.24.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1631727872, 1648505088]\n",
      "  model.layers.24.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1648505088, 1665282304]\n",
      "  model.layers.24.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1665282304, 1682059520]\n",
      "  model.layers.24.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1682059520, 1682063616]\n",
      "  model.layers.24.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1682063616, 1682067712]\n",
      "  model.layers.24.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1682067712, 1682067840]\n",
      "  model.layers.24.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1682067840, 1684164992]\n",
      "  model.layers.24.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1684164992, 1692553600]\n",
      "  model.layers.24.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1692553600, 1692553728]\n",
      "  model.layers.24.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1692553728, 1700942336]\n",
      "  model.layers.24.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1700942336, 1703039488]\n",
      "  model.layers.25.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1703039488, 1719816704]\n",
      "  model.layers.25.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1719816704, 1736593920]\n",
      "  model.layers.25.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1736593920, 1753371136]\n",
      "  model.layers.25.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1753371136, 1753375232]\n",
      "  model.layers.25.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1753375232, 1753379328]\n",
      "  model.layers.25.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1753379328, 1753379456]\n",
      "  model.layers.25.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1753379456, 1755476608]\n",
      "  model.layers.25.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1755476608, 1763865216]\n",
      "  model.layers.25.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1763865216, 1763865344]\n",
      "  model.layers.25.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1763865344, 1772253952]\n",
      "  model.layers.25.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1772253952, 1774351104]\n",
      "  model.layers.26.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1774351104, 1791128320]\n",
      "  model.layers.26.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1791128320, 1807905536]\n",
      "  model.layers.26.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1807905536, 1824682752]\n",
      "  model.layers.26.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1824682752, 1824686848]\n",
      "  model.layers.26.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1824686848, 1824690944]\n",
      "  model.layers.26.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1824690944, 1824691072]\n",
      "  model.layers.26.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1824691072, 1826788224]\n",
      "  model.layers.26.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1826788224, 1835176832]\n",
      "  model.layers.26.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1835176832, 1835176960]\n",
      "  model.layers.26.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1835176960, 1843565568]\n",
      "  model.layers.26.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1843565568, 1845662720]\n",
      "  model.layers.27.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1845662720, 1862439936]\n",
      "  model.layers.27.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1862439936, 1879217152]\n",
      "  model.layers.27.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1879217152, 1895994368]\n",
      "  model.layers.27.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1895994368, 1895998464]\n",
      "  model.layers.27.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1895998464, 1896002560]\n",
      "  model.layers.27.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1896002560, 1896002688]\n",
      "  model.layers.27.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1896002688, 1898099840]\n",
      "  model.layers.27.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1898099840, 1906488448]\n",
      "  model.layers.27.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1906488448, 1906488576]\n",
      "  model.layers.27.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1906488576, 1914877184]\n",
      "  model.layers.27.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1914877184, 1916974336]\n",
      "  model.layers.28.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1916974336, 1933751552]\n",
      "  model.layers.28.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1933751552, 1950528768]\n",
      "  model.layers.28.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [1950528768, 1967305984]\n",
      "  model.layers.28.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1967305984, 1967310080]\n",
      "  model.layers.28.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [1967310080, 1967314176]\n",
      "  model.layers.28.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1967314176, 1967314304]\n",
      "  model.layers.28.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1967314304, 1969411456]\n",
      "  model.layers.28.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1969411456, 1977800064]\n",
      "  model.layers.28.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [1977800064, 1977800192]\n",
      "  model.layers.28.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [1977800192, 1986188800]\n",
      "  model.layers.28.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [1986188800, 1988285952]\n",
      "  model.layers.29.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [1988285952, 2005063168]\n",
      "  model.layers.29.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2005063168, 2021840384]\n",
      "  model.layers.29.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2021840384, 2038617600]\n",
      "  model.layers.29.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2038617600, 2038621696]\n",
      "  model.layers.29.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2038621696, 2038625792]\n",
      "  model.layers.29.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2038625792, 2038625920]\n",
      "  model.layers.29.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2038625920, 2040723072]\n",
      "  model.layers.29.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2040723072, 2049111680]\n",
      "  model.layers.29.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2049111680, 2049111808]\n",
      "  model.layers.29.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2049111808, 2057500416]\n",
      "  model.layers.29.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2057500416, 2059597568]\n",
      "  model.layers.3.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2059597568, 2076374784]\n",
      "  model.layers.3.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2076374784, 2093152000]\n",
      "  model.layers.3.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2093152000, 2109929216]\n",
      "  model.layers.3.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2109929216, 2109933312]\n",
      "  model.layers.3.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2109933312, 2109937408]\n",
      "  model.layers.3.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2109937408, 2109937536]\n",
      "  model.layers.3.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2109937536, 2112034688]\n",
      "  model.layers.3.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2112034688, 2120423296]\n",
      "  model.layers.3.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2120423296, 2120423424]\n",
      "  model.layers.3.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2120423424, 2128812032]\n",
      "  model.layers.3.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2128812032, 2130909184]\n",
      "  model.layers.4.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2130909184, 2147686400]\n",
      "  model.layers.4.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2147686400, 2164463616]\n",
      "  model.layers.4.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2164463616, 2181240832]\n",
      "  model.layers.4.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2181240832, 2181244928]\n",
      "  model.layers.4.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2181244928, 2181249024]\n",
      "  model.layers.4.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2181249024, 2181249152]\n",
      "  model.layers.4.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2181249152, 2183346304]\n",
      "  model.layers.4.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2183346304, 2191734912]\n",
      "  model.layers.4.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2191734912, 2191735040]\n",
      "  model.layers.4.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2191735040, 2200123648]\n",
      "  model.layers.4.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2200123648, 2202220800]\n",
      "  model.layers.5.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2202220800, 2218998016]\n",
      "  model.layers.5.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2218998016, 2235775232]\n",
      "  model.layers.5.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2235775232, 2252552448]\n",
      "  model.layers.5.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2252552448, 2252556544]\n",
      "  model.layers.5.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2252556544, 2252560640]\n",
      "  model.layers.5.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2252560640, 2252560768]\n",
      "  model.layers.5.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2252560768, 2254657920]\n",
      "  model.layers.5.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2254657920, 2263046528]\n",
      "  model.layers.5.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2263046528, 2263046656]\n",
      "  model.layers.5.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2263046656, 2271435264]\n",
      "  model.layers.5.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2271435264, 2273532416]\n",
      "  model.layers.6.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2273532416, 2290309632]\n",
      "  model.layers.6.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2290309632, 2307086848]\n",
      "  model.layers.6.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2307086848, 2323864064]\n",
      "  model.layers.6.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2323864064, 2323868160]\n",
      "  model.layers.6.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2323868160, 2323872256]\n",
      "  model.layers.6.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2323872256, 2323872384]\n",
      "  model.layers.6.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2323872384, 2325969536]\n",
      "  model.layers.6.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2325969536, 2334358144]\n",
      "  model.layers.6.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2334358144, 2334358272]\n",
      "  model.layers.6.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2334358272, 2342746880]\n",
      "  model.layers.6.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2342746880, 2344844032]\n",
      "  model.layers.7.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2344844032, 2361621248]\n",
      "  model.layers.7.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2361621248, 2378398464]\n",
      "  model.layers.7.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2378398464, 2395175680]\n",
      "  model.layers.7.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2395175680, 2395179776]\n",
      "  model.layers.7.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2395179776, 2395183872]\n",
      "  model.layers.7.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2395183872, 2395184000]\n",
      "  model.layers.7.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2395184000, 2397281152]\n",
      "  model.layers.7.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2397281152, 2405669760]\n",
      "  model.layers.7.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2405669760, 2405669888]\n",
      "  model.layers.7.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2405669888, 2414058496]\n",
      "  model.layers.7.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2414058496, 2416155648]\n",
      "  model.layers.8.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2416155648, 2432932864]\n",
      "  model.layers.8.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2432932864, 2449710080]\n",
      "  model.layers.8.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2449710080, 2466487296]\n",
      "  model.layers.8.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2466487296, 2466491392]\n",
      "  model.layers.8.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2466491392, 2466495488]\n",
      "  model.layers.8.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2466495488, 2466495616]\n",
      "  model.layers.8.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2466495616, 2468592768]\n",
      "  model.layers.8.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2468592768, 2476981376]\n",
      "  model.layers.8.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2476981376, 2476981504]\n",
      "  model.layers.8.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2476981504, 2485370112]\n",
      "  model.layers.8.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2485370112, 2487467264]\n",
      "  model.layers.9.mlp.down_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 4096]\n",
      "    data_offsets: [2487467264, 2504244480]\n",
      "  model.layers.9.mlp.gate_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2504244480, 2521021696]\n",
      "  model.layers.9.mlp.up_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [4096, 2048]\n",
      "    data_offsets: [2521021696, 2537798912]\n",
      "  model.layers.9.post_attention_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2537798912, 2537803008]\n",
      "  model.layers.9.post_feedforward_layernorm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2537803008, 2537807104]\n",
      "  model.layers.9.self_attn.k_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2537807104, 2537807232]\n",
      "  model.layers.9.self_attn.k_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2537807232, 2539904384]\n",
      "  model.layers.9.self_attn.o_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2539904384, 2548292992]\n",
      "  model.layers.9.self_attn.q_norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [64]\n",
      "    data_offsets: [2548292992, 2548293120]\n",
      "  model.layers.9.self_attn.q_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048, 2048]\n",
      "    data_offsets: [2548293120, 2556681728]\n",
      "  model.layers.9.self_attn.v_proj.weight:\n",
      "    dtype: BF16\n",
      "    shape: [512, 2048]\n",
      "    data_offsets: [2556681728, 2558778880]\n",
      "  model.norm.weight:\n",
      "    dtype: BF16\n",
      "    shape: [2048]\n",
      "    data_offsets: [2558778880, 2558782976]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from safetensors import safe_open\n",
    "\n",
    "def inspect_safetensor_header(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        #  8   \n",
    "        header_size = int.from_bytes(f.read(8), 'little')\n",
    "        \n",
    "        #  \n",
    "        header = json.loads(f.read(header_size))\n",
    "        \n",
    "        print(\"Safetensor Header:\")\n",
    "        print(json.dumps(header, indent=2))\n",
    "        \n",
    "        # tensor  \n",
    "        if '__metadata__' in header:\n",
    "            print(\"\\n**************************Metadata:\")\n",
    "            for key, value in header['__metadata__'].items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        print(\"\\n**************************Tensors:\")\n",
    "        for key, info in header.items():\n",
    "            if key != '__metadata__':\n",
    "                print(f\"  {key}:\")\n",
    "                print(f\"    dtype: {info['dtype']}\")\n",
    "                print(f\"    shape: {info['shape']}\")\n",
    "                print(f\"    data_offsets: {info['data_offsets']}\")\n",
    "\n",
    "#  \n",
    "model_path = \"/home/sparkleholic/.cache/huggingface/hub/models--LGAI-EXAONE--EXAONE-4.0-1.2B/snapshots/e1bc152ddee871e02a4b91826a700898686c2012/model.safetensors\"\n",
    "inspect_safetensor_header(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6217329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/sparkleholic/.cache/huggingface/hub/models--LGAI-EXAONE--EXAONE-3.5-2.4B-Instruct/snapshots/e949c91dec92095908d34e6b560af77dd0c993f8/model-00001-of-00002.safetensors\"\n",
    "inspect_safetensor_header(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b50cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chktok: [560, 582, 560, 560, 582, 560, 560, 560, 582, 559, 582, 41, 582, 559, 560, 33, 560, 32, 560, 31, 560, 30, 560, 11881, 610, 584, 688, 13528, 370, 38961, 476, 45433, 11881, 596, 466, 533, 76100, 688, 87333, 97354, 648, 86597, 370, 78177, 14901, 461, 609, 11881, 461, 609, 582, 380, 582, 380, 380, 582, 380, 380, 380, 582, 380, 380, 380, 380, 582, 380, 380, 380, 380, 380, 582, 380, 380, 380, 380, 380, 380, 582, 380, 380, 380, 380, 380, 380, 380, 582, 380, 380, 380, 380, 380, 380, 380, 380, 582, 380, 375, 380, 582, 380, 951, 380, 582, 380, 4087, 380, 62775, 584, 35149, 476, 35149, 603, 68853, 595, 35149, 599, 68853, 586, 35149, 606, 35149, 477, 35149, 615, 68853, 585, 35149, 615, 35149, 457, 35149, 476, 35149, 589, 11881, 608, 585, 908, 48118, 57583, 19762, 46295, 55482, 20958, 378, 380, 378, 381, 378, 382, 378, 45152, 533, 483, 614, 31744, 24486, 23638, 23573, 2658, 19569, 58635, 44182, 5405, 19629, 24556, 21851, 3341, 5740, 7925, 7925, 77782, 5232, 2281, 2281, 52639, 55202, 3461, 61709, 6567, 768, 368, 777, 1441, 741, 67753, 1028, 368, 444, 1410, 373, 741, 4582, 904, 3770, 392, 741, 406, 1017, 3770, 768, 368, 1373, 2087, 885, 373, 741, 397, 904, 1664, 1364, 16211, 392, 1660, 368, 37494, 619, 368, 437, 405]\n",
      "chkhsh: 2085e1638f6c377a0aa4ead21b27bb4cb941bf800df86ed391011769c1758dfb\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hashlib import sha256\n",
    "\n",
    "#     (  )\n",
    "model_dir = \"/home/sparkleholic/.cache/huggingface/hub/models--LGAI-EXAONE--EXAONE-4.0-1.2B/snapshots/e1bc152ddee871e02a4b91826a700898686c2012\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "#   (  )\n",
    "chktxt = '\\n \\n\\n \\n\\n\\n \\t \\t\\t \\t\\n  \\n   \\n    \\n     \\n (normal) \\u200d (multiple emojis concatenated)   3 33 333 3333 33333 333333 3333333 33333333 3.3 3..3 3...3  ?apple1314151 ------=======    \\'\\'\\'\\'\\'\\'```````\"\"\"\"......!!!!!!?????? I\\'ve been \\'told he\\'s there, \\'RE you sure? \\'M not sure I\\'ll make it, \\'D you like some tea? We\\'Ve a\\'lL'\n",
    "\n",
    "#    \n",
    "chktok = tokenizer.encode(chktxt)\n",
    "chkhsh = sha256(str(chktok).encode()).hexdigest()\n",
    "\n",
    "print(f\"chktok: {chktok}\")\n",
    "print(f\"chkhsh: {chkhsh}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
